{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ca8e2f9",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Zoals eerder vermeld, zijn er twee basis stappen in machine learning:\n",
    "1. Model training\n",
    "2. Model inference\n",
    "\n",
    "Op het moment dat we een model hebben gedefini√´erd, willen we de parameters aan de hand van de beschikbare data schatten. Dat doen we door het gepaste leer-algorithme toe te passen.\n",
    "Dit noemen we **model training**.  \n",
    "  \n",
    "Een **getrained model is een model waarvan de parameters geschat zijn met behulp van een wel bepaalde traing dataset en optimalisatie-algorithme**.\n",
    "\n",
    "Pas als het model getrained is, kan het gebruikt worden om effectief patroonherkenning te doen op _nieuwe data_. Die stap heet _model inference_.\n",
    "\n",
    ":::{warning}\n",
    "Het is niet omdat we een getraind model hebben, dat dit automatisch betekent dat het in staat is om de patronen te herkennen waar we naar op zoek zijn!  \n",
    "**Onthou**: _All models are wrong, some are useful_.\n",
    ":::\n",
    "\n",
    "### Optimalisatie-algorithme\n",
    "Een optimalisatie-algorithme heeft als doel om de optimale waarde voor een parameter te vinden, gegeven ons model (van de werkelijkheid) en de beschikbare data.\n",
    "_Bij het uitvoeren van het optimalisatie-algorithme gebeurt dus het eigenlijke leren in ML_. Ook hier zijn vaak verschillende keuzes aan de orde.\n",
    "Daarbij moeten we (a) effectiviteit om juiste parameterwaarden te vinden en (b) computationele efficientie tegen elkaar afgewegen.\n",
    "\n",
    ":::{note} üåç\n",
    ":icon: false\n",
    ":class: simple \n",
    "In ons eennvoudige airco voorbeeld kozen we voor het sample gemiddelde.\n",
    ":::\n",
    "\n",
    "De keuze van het algorithme hangt samen met het type model (lineair, neuraal netwerk, random forest, enz.) en, hoewel er voortdurend verder onderzoek gebeurd naar nieuwe technieken, zijn voor veel modellen geijkte keuzes beschikbaar. \n",
    "Zoals we in de uitgebreidere voorbeelden ook zullen zien, zijn leer- of optimalisatiealgorithmes vaak zeer complex (denk alvast aan het [backpropagation](https://en.wikipedia.org/wiki/Backpropagation) algoritme bij neurale netwerken en uitgebreid aan bod komt in de cursus Mathematical Foundations).  \n",
    "In die complexiteit zit vaak ook nog het feit dat er verdere keuzes moeten gemaakt worden met betrekking tot de _specifieke configuratie van het algorithme zelf_.\n",
    "Bij iteratieve methodes, bijvoorbeeld, waarin er stapsgewijs gezocht wordt naar een optimale waarde, moeten we een keuze maken over de grootte van die stappen (de zogenaamde _learning rate_).  \n",
    "Die configuratie kan een grote impact hebben op de kwaliteit van het uiteindelijke resultaat. Het is vaak op voorhand ook niet duidelijk welke de beste configuratie voor het optimalisatie algorithme is, gegeven de specifieke situatie. Daarom wordt ook daar vaak op een (al dan niet principi√´le manier) iteratief gewerkt om tot optimale waarden te komen.  \n",
    "**De numerieke configuratie parameters van een optimalisatiealgorithme worden _hyper parameters_ genoemd. Het process waarbij de hyper parameters worden geoptimaliseerd heeft _hyper parameter tuning_.**  \n",
    "  \n",
    ":::{note} üåç\n",
    ":icon: false\n",
    ":class: simple \n",
    "Veronder stel dat we voor ons eenvoudigste model voor de airco temperatuur drempelwaarde het volgende na√Øeve algorithme zouden gebruiken in plaats van het sample gemiddelde:\n",
    "- We starten met een berekende gok, bv. $\\hat{b_0} = 18$\n",
    "- Van zodra de eerste observatie gemaakt wordt, bv. $d_0 = 25$, willen we onze initi√´le schatting updaten, maar we willen uiteraard niet gewoon de geobserveerde waarde overnemen.\n",
    "- We kiezen voor de techniek van _expontial smoothing_ waarbij we op ieder moment een gewogen gemiddelde nemen tussen onze schatting van dat moment $\\hat{b_i}$ en de nieuwe observatie $d_i$.\n",
    "$$\n",
    "\\hat{b_{i+1}} = \\hat{b_i}*\\alpha + d_i*(1-\\alpha) \\\\\n",
    "0 > \\alpha > 1\n",
    "$$\n",
    "\n",
    "Hieronder visualiseren we dit voor verschillende waarden voor $\\hat{b_0}$ en $\\alpha$.\n",
    ":::\n",
    "\n",
    ":::{note} üåç\n",
    ":icon: false\n",
    ":class: simple\n",
    "In dit algorithme spreken we dus over 2 **hyper parameters**: $\\hat{b_0}$ en $\\alpha$. De keuze daarvan heeft duidelijk drastische gevolgen voor de convergentie van het leerprocess.\n",
    "Als we op een bepaald moment de schatting van de model parameter $\\hat{b}$ willen vastzetten (zgn. _parameter freezing_), kunnen het algorithme ook uitbreiden met een zgn. _stopping rule_.\n",
    "Die regel bepaald de voorwaarde om de updates te stoppen. Dat kan heel simpel door toevoeging van een hyper parameter die het maximum aantal updates bepaalt of door bijvoorbeeld een limiet te zetten op de _online_ update variantie (bv. [](https://doi.org/10.2307%2F1266577))\n",
    ":::\n",
    "\n",
    "### Supervisie\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22b2fce",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
